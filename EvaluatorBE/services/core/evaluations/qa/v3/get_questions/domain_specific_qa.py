from typing import Dict, List
from services.ai.agents.domain_specific_qa.autogenerated_questions_qa_agent import (
    domain_specific_qa_agent,
    Question,
)
from sqlalchemy.orm import Session
from db.models.evaluation_step import EvaluationStep
from db.models.user_evaluation import UserEvaluation
from db.models.chat_session import ChatSession
from db.models.chat_history import ChatHistory
from services.core.evaluations.qa.v3.get_questions.project_specific_qa import (
    project_specific_qa,
)
from services.core.evaluations.qa.v3.get_questions.predefined_questions_domain_specific import (
    predefined_questions_qa_agent,
)
from db.chat_history import get_chat_history
from db.models.evaluation import Evaluation
from fastapi import BackgroundTasks, UploadFile, Response
from services.ai.speech_processing.speech_to_text import convert_speech_to_text
import json
from services.ai.agents.eleven_labs.text_to_audio import convert_text_to_audio
from fastapi.responses import JSONResponse
import base64


def domain_specific_qa(
    chat_id: int,
    number_of_questions: int,
    db: Session,
    response_queues: Dict[int, List[Dict]],
):

    user_evaluation_id: int = (
        db.query(ChatSession).where(ChatSession.id == chat_id).first().userevaluation_id
    )

    userEvaluation: UserEvaluation = (
        db.query(UserEvaluation).where(UserEvaluation.id == user_evaluation_id).first()
    )

    chatSession: ChatSession = (
        db.query(ChatSession).where(ChatSession.id == chat_id).first()
    )

    evaluation = (
        db.query(Evaluation)
        .where(Evaluation.id == userEvaluation.evaluation_id)
        .first()
    )

    if (
        db.query(EvaluationStep)
        .where(EvaluationStep.step_name == "domain_specific_qa")
        .where(EvaluationStep.userevaluation_id == userEvaluation.id)
        .first()
        != None
    ):

        return {
            "question": None,
            "is_complete": True,
            "errors": ["evaluation already completed"],
            "viva_type": "domain_specific_qa",
        }

    if evaluation.questions == None:
        return {
            "question": None,
            "is_complete": True,
            "errors": ["No questions available for this evaluation"],
            "viva_type": "domain_specific_qa",
        }
    else:
        list_of_questions = predefined_questions_qa_agent(
            session_id=chat_id,
            list_of_questions=evaluation.questions,
            domain_name=evaluation.track_name,
            number_of_questions=number_of_questions,
            response_queues=response_queues,
        )
        return {
            "question": list_of_questions,
            "is_complete": False,
            "errors": [],
            "viva_type": "domain_specific_qa",
        }
